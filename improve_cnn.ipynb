{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajitha-SL/My-AI-Projects/blob/AI-and-ML-learning/improve_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_MDQ1rRV4zO"
      },
      "source": [
        "# Improving Performances\n",
        "\n",
        "Now that we have seen some tricks to improve performances of a CNN, let's apply them to the CIFAR10 dataset that we used in our previous exercise.\n",
        "\n",
        "To keep things simple, we will optimize two hyperparameters.\n",
        "\n",
        "For our data augmentation, we are going to use the `RandAugment` [auto-augmentation policy](https://pytorch.org/vision/main/generated/torchvision.transforms.RandAugment.html) which only takes one parameter, called `magnitude`. This parameter will be one of the parameters we will optimize in our hyperparameter search.\n",
        "\n",
        "We will also optimize the learning rate for the gradient descent.\n",
        "\n",
        "When doing hyperparameter optimization, it is important to have high-level functions (or scripts) that receive our hyperparameters as inputs, so we can run as many training runs as we need by only varying the calling to the function (or the script). Of course, this would not work if we were to hard-code the parameters.\n",
        "\n",
        "Ok, enough with the introduction, let's get started!\n",
        "\n",
        "As usual, let's start by installing our requirements:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "vnIRh_ryYnKN",
        "outputId": "ea41c44b-6c44-4cc0-db63-0603be2fbffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7201a2f-fcd0-4e94-97cc-c8a24d6a763c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e7201a2f-fcd0-4e94-97cc-c8a24d6a763c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving lr_finder.py to lr_finder (1).py\n",
            "Saving helpers.py to helpers (1).py\n",
            "Saving requirements.txt to requirements (1).txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lr_finder (1).py': b'import torch\\nimport numpy as np\\nfrom torch.optim.lr_scheduler import LambdaLR\\nfrom tqdm import tqdm\\nimport torch.optim as optim\\nimport copy\\n\\n\\ndef lr_finder(min_lr, max_lr, n_steps, loss, model, data_loaders):\\n    \\n    # Save initial weights so we can restore them at the end\\n    torch.save(model.state_dict(), \"__weights_backup\")\\n    \\n    # specify optimizer\\n    optimizer = optim.SGD(model.parameters(), lr=min_lr)\\n\\n    # We create a learning rate scheduler that increases the learning\\n    # rate at every batch.\\n    # Find the factor where min_lr r**(n_steps-1) = max_lr\\n    r = np.power(max_lr / min_lr, 1 / (n_steps - 1))\\n\\n    def new_lr(epoch):\\n        \"\"\"\\n        This should return the *factor* by which the initial learning\\n        rate must be multipled for to get the desired learning rate\\n        \"\"\"\\n        return r ** epoch\\n\\n    # This scheduler increases the learning rate by a constanct factor (r)\\n    # at every iteration\\n    lr_scheduler = LambdaLR(optimizer, new_lr)\\n\\n    # Set the model in training mode\\n    # (so all layers that behave differently between training and evaluation,\\n    # like batchnorm and dropout, will select their training behavior)\\n    model.train()\\n\\n    # Loop over the training data\\n    losses = {}\\n    train_loss = 0.0\\n\\n    for batch_idx, (data, target) in tqdm(\\n        enumerate(data_loaders[\"train\"]),\\n        desc=\"Training\",\\n        total=len(data_loaders[\"train\"]),\\n        leave=True,\\n        ncols=80,\\n    ):\\n        # move data to GPU if available\\n        if torch.cuda.is_available():\\n            data, target = data.cuda(), target.cuda()\\n\\n        # 1. clear the gradients of all optimized variables\\n        optimizer.zero_grad()  # -\\n        # 2. forward pass: compute predicted outputs by passing inputs to the model\\n        output = model(data)  # =\\n        # 3. calculate the loss\\n        loss_value = loss(output, target)  # =\\n        # 4. backward pass: compute gradient of the loss with respect to model parameters\\n        loss_value.backward()  # -\\n        # 5. perform a single optimization step (parameter update)\\n        optimizer.step()  # -\\n\\n        train_loss = train_loss + (\\n            (1 / (batch_idx + 1)) * (loss_value.data.item() - train_loss)\\n        )\\n\\n        losses[lr_scheduler.get_last_lr()[0]] = train_loss\\n\\n        # Stop if the loss gets too big\\n        if train_loss / min(losses.values()) > 10:\\n            break\\n\\n        if batch_idx == n_steps - 1:\\n            break\\n        else:\\n            # Increase the learning rate for the next iteration\\n            lr_scheduler.step()\\n    \\n    # Restore model to its initial state\\n    model.load_state_dict(torch.load(\\'__weights_backup\\'))\\n    \\n    return losses\\n',\n",
              " 'helpers (1).py': b'import matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\nimport torch\\nfrom livelossplot import PlotLosses\\nfrom livelossplot.outputs import MatplotlibPlot\\nfrom torch.utils.data.sampler import SubsetRandomSampler\\nfrom torchvision import datasets\\nfrom tqdm import tqdm\\n\\n\\ndef get_train_val_data_loaders(batch_size, valid_size, transforms, num_workers):\\n\\n    # Get the CIFAR10 training dataset from torchvision.datasets and set the transforms\\n    # We will split this further into train and validation in this function\\n    train_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms)\\n\\n    # Compute how many items we will reserve for the validation set\\n    n_tot = len(train_data)\\n    split = int(np.floor(valid_size * n_tot))\\n\\n    # compute the indices for the training set and for the validation set\\n    shuffled_indices = torch.randperm(n_tot)\\n    train_idx, valid_idx = shuffled_indices[split:], shuffled_indices[:split]\\n\\n    # define samplers for obtaining training and validation batches\\n    train_sampler = SubsetRandomSampler(train_idx)\\n    valid_sampler = SubsetRandomSampler(valid_idx)\\n\\n    # prepare data loaders (combine dataset and sampler)\\n    train_loader = torch.utils.data.DataLoader(\\n        train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers\\n    )\\n    valid_loader = torch.utils.data.DataLoader(\\n        train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers\\n    )\\n\\n    return train_loader, valid_loader\\n\\n\\ndef get_test_data_loader(batch_size, transforms, num_workers):\\n    # We use the entire test dataset in the test dataloader\\n    test_data = datasets.CIFAR10(\"data\", train=False, download=True, transform=transforms)\\n    test_loader = torch.utils.data.DataLoader(\\n        test_data, batch_size=batch_size, num_workers=num_workers\\n    )\\n\\n    return test_loader\\n\\n\\ndef train_one_epoch(train_dataloader, model, optimizer, loss):\\n    \"\"\"\\n    Performs one epoch of training\\n    \"\"\"\\n\\n    # Move model to GPU if available\\n    if torch.cuda.is_available():\\n        model.cuda()  # -\\n\\n    # Set the model in training mode\\n    # (so all layers that behave differently between training and evaluation,\\n    # like batchnorm and dropout, will select their training behavior)\\n    model.train()  # -\\n\\n    # Loop over the training data\\n    train_loss = 0.0\\n\\n    for batch_idx, (data, target) in tqdm(\\n        enumerate(train_dataloader),\\n        desc=\"Training\",\\n        total=len(train_dataloader),\\n        leave=True,\\n        ncols=80,\\n    ):\\n        # move data to GPU if available\\n        if torch.cuda.is_available():\\n            data, target = data.cuda(), target.cuda()\\n\\n        # 1. clear the gradients of all optimized variables\\n        optimizer.zero_grad()  # -\\n        # 2. forward pass: compute predicted outputs by passing inputs to the model\\n        output = model(data)  # =\\n        # 3. calculate the loss\\n        loss_value = loss(output, target)  # =\\n        # 4. backward pass: compute gradient of the loss with respect to model parameters\\n        loss_value.backward()  # -\\n        # 5. perform a single optimization step (parameter update)\\n        optimizer.step()  # -\\n\\n        # update average training loss\\n        train_loss = train_loss + (\\n            (1 / (batch_idx + 1)) * (loss_value.data.item() - train_loss)\\n        )\\n\\n    return train_loss\\n\\n\\ndef valid_one_epoch(valid_dataloader, model, loss):\\n    \"\"\"\\n    Validate at the end of one epoch\\n    \"\"\"\\n\\n    # During validation we don\\'t need to accumulate gradients\\n    with torch.no_grad():\\n\\n        # set the model to evaluation mode\\n        # (so all layers that behave differently between training and evaluation,\\n        # like batchnorm and dropout, will select their evaluation behavior)\\n        model.eval()  # -\\n\\n        # If the GPU is available, move the model to the GPU\\n        if torch.cuda.is_available():\\n            model.cuda()\\n\\n        # Loop over the validation dataset and accumulate the loss\\n        valid_loss = 0.0\\n        for batch_idx, (data, target) in tqdm(\\n            enumerate(valid_dataloader),\\n            desc=\"Validating\",\\n            total=len(valid_dataloader),\\n            leave=True,\\n            ncols=80,\\n        ):\\n            # move data to GPU if available\\n            if torch.cuda.is_available():\\n                data, target = data.cuda(), target.cuda()\\n\\n            # 1. forward pass: compute predicted outputs by passing inputs to the model\\n            output = model(data)  # =\\n            # 2. calculate the loss\\n            loss_value = loss(output, target)  # =\\n\\n            # Calculate average validation loss\\n            valid_loss = valid_loss + (\\n                (1 / (batch_idx + 1)) * (loss_value.data.item() - valid_loss)\\n            )\\n\\n    return valid_loss\\n\\n\\ndef optimize(data_loaders, model, optimizer, loss, n_epochs, save_path, interactive_tracking=False):\\n    # initialize tracker for minimum validation loss\\n    if interactive_tracking:\\n        liveloss = PlotLosses()\\n    else:\\n        liveloss = None\\n\\n    # Loop over the epochs and keep track of the minimum of the validation loss\\n    valid_loss_min = None\\n    logs = {}\\n\\n    for epoch in range(1, n_epochs + 1):\\n\\n        train_loss = train_one_epoch(\\n            data_loaders[\"train\"], model, optimizer, loss\\n        )\\n\\n        valid_loss = valid_one_epoch(data_loaders[\"valid\"], model, loss)\\n\\n        # print training/validation statistics\\n        print(\\n            \"Epoch: {} \\\\tTraining Loss: {:.6f} \\\\tValidation Loss: {:.6f}\".format(\\n                epoch, train_loss, valid_loss\\n            )\\n        )\\n\\n        # If the validation loss decreases by more than 1%, save the model\\n        if valid_loss_min is None or (\\n                (valid_loss_min - valid_loss) / valid_loss_min > 0.01\\n        ):\\n            print(f\"New minimum validation loss: {valid_loss:.6f}. Saving model ...\")\\n\\n            # Save the weights to save_path\\n            torch.save(model.state_dict(), save_path)  # -\\n\\n            valid_loss_min = valid_loss\\n\\n        # Log the losses and the current learning rate\\n        if interactive_tracking:\\n            logs[\"loss\"] = train_loss\\n            logs[\"val_loss\"] = valid_loss\\n\\n            liveloss.update(logs)\\n            liveloss.send()\\n\\n            \\ndef one_epoch_test(test_dataloader, model, loss):\\n    # monitor test loss and accuracy\\n    test_loss = 0.\\n    correct = 0.\\n    total = 0.\\n\\n    # we do not need the gradients\\n    with torch.no_grad():\\n\\n        # set the model to evaluation mode\\n        model.eval()  # -\\n\\n        # if the GPU is available, move the model to the GPU\\n        if torch.cuda.is_available():\\n            model = model.cuda()\\n\\n        # Loop over test dataset\\n        # We also accumulate predictions and targets so we can return them\\n        preds = []\\n        actuals = []\\n        \\n        for batch_idx, (data, target) in tqdm(\\n                enumerate(test_dataloader),\\n                desc=\\'Testing\\',\\n                total=len(test_dataloader),\\n                leave=True,\\n                ncols=80\\n        ):\\n            # move data to GPU if available\\n            if torch.cuda.is_available():\\n                data, target = data.cuda(), target.cuda()\\n\\n            # 1. forward pass: compute predicted outputs by passing inputs to the model\\n            logits = model(data)  # =\\n            # 2. calculate the loss\\n            loss_value = loss(logits, target).detach()  # =\\n\\n            # update average test loss\\n            test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss_value.data.item() - test_loss))\\n\\n            # convert logits to predicted class\\n            # NOTE: the predicted class is the index of the max of the logits\\n            pred = logits.data.max(1, keepdim=True)[1]  # =\\n\\n            # compare predictions to true label\\n            correct += torch.sum(torch.squeeze(pred.eq(target.data.view_as(pred))).cpu())\\n            total += data.size(0)\\n            \\n            preds.extend(pred.data.cpu().numpy().squeeze())\\n            actuals.extend(target.data.view_as(pred).cpu().numpy().squeeze())\\n\\n    print(\\'Test Loss: {:.6f}\\\\n\\'.format(test_loss))\\n\\n    print(\\'\\\\nTest Accuracy: %2d%% (%2d/%2d)\\' % (\\n        100. * correct / total, correct, total))\\n\\n    return test_loss, preds, actuals\\n\\n\\ndef plot_confusion_matrix(pred, truth, classes):\\n\\n    gt = pd.Series(truth, name=\\'Ground Truth\\')\\n    predicted = pd.Series(pred, name=\\'Predicted\\')\\n\\n    confusion_matrix = pd.crosstab(gt, predicted)\\n    confusion_matrix.index = classes\\n    confusion_matrix.columns = classes\\n    \\n    fig, sub = plt.subplots()\\n    with sns.plotting_context(\"notebook\"):\\n\\n        ax = sns.heatmap(\\n            confusion_matrix, \\n            annot=True, \\n            fmt=\\'d\\',\\n            ax=sub, \\n            linewidths=0.5, \\n            linecolor=\\'lightgray\\', \\n            cbar=False\\n        )\\n        ax.set_xlabel(\"truth\")\\n        ax.set_ylabel(\"pred\")\\n\\n    \\n\\n    return confusion_matrix\\n',\n",
              " 'requirements (1).txt': b'opencv-python-headless==4.5.3.56\\nmatplotlib==3.4.3\\nnumpy==1.21.2\\npillow==7.0.0\\nbokeh==2.1.1\\ntorch==1.11.0\\ntorchvision==0.12.0\\ntqdm==4.63.0\\nipywidgets==7.6.5\\nlivelossplot==0.5.4\\npytest==7.1.1\\npandas==1.3.5\\nseaborn==0.11.2\\nmlflow==1.25.1'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJg6NeBPV4zS",
        "outputId": "281fb0f4-4ee4-477e-c5b8-b7d5237486fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pmr5aDPV4zW"
      },
      "source": [
        "Let's also make sure that the GPU is active (otherwise things will be _very_ slow):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYTd-QJxV4zX",
        "outputId": "df82e178-1c56-4e30-cec6-babab645c4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AZoR-gxV4zY"
      },
      "source": [
        "---\n",
        "## Data Augmentation\n",
        "\n",
        "Here we write two functions that create appropriate transforms for the training, validation and test datasets, and then create the relative dataloaders.\n",
        "\n",
        "As usual, complete the code in the sections marked with `# YOUR CODE HERE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAB-6J2ZV4zY",
        "outputId": "95ffdbe4-3734-44a0-8b9c-445490159254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.22.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (23.1)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.5.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.1)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2023.7.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install livelossplot\n",
        "import torchvision.transforms as T\n",
        "from torchvision import datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "import multiprocessing\n",
        "from helpers import get_train_val_data_loaders, get_test_data_loader\n",
        "import torch.multiprocessing\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "\n",
        "# Let's write a function that gives us the transforms so we can optimize the hyperparameters\n",
        "def get_transforms(rand_augment_magnitude):\n",
        "\n",
        "    # These are the per-channel mean and std of CIFAR-10 over the dataset\n",
        "    mean = (0.49139968, 0.48215827, 0.44653124)\n",
        "    std = (0.24703233, 0.24348505, 0.26158768)\n",
        "\n",
        "    # Define our transformations\n",
        "    return {\n",
        "        \"train\": T.Compose(\n",
        "            [\n",
        "                # All images in CIFAR-10 are 32x32. We enlarge them a bit so we can then\n",
        "                # take a random crop\n",
        "                T.Resize(40),\n",
        "\n",
        "                # take a random part of the image\n",
        "                T.RandomCrop(32),\n",
        "\n",
        "                # Horizontal flip is not part of RandAugment according to the RandAugment\n",
        "                # paper\n",
        "                T.RandomHorizontalFlip(0.5),\n",
        "\n",
        "                # Use RandAugment\n",
        "                # RandAugment has 2 main parameters: how many transformations should be\n",
        "                # applied to each image, and the strength of these transformations. This\n",
        "                # latter parameter should be tuned through experiments: the higher the more\n",
        "                # the regularization effect.\n",
        "                # Setup a T.RandAugment transformation using 2 as num_opts, and the\n",
        "                # rand_augment_magnitude input parameter as magnitude.\n",
        "                # Use T.InterpolationMode.BILINEAR as interpolation. Look at the pytorch\n",
        "                # manual if needed:\n",
        "                # https://pytorch.org/vision/main/generated/torchvision.transforms.RandAugment.html\n",
        "\n",
        "                T.RandAugment(num_ops= 2, magnitude= 9, num_magnitude_bins= 31, interpolation= T.InterpolationMode.BILINEAR),\n",
        "\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean, std),\n",
        "            ]\n",
        "        ),\n",
        "        \"valid\": T.Compose(\n",
        "            [\n",
        "                # Both of these are useless, but we keep them because\n",
        "                # in a non-academic dataset you will need them\n",
        "                T.Resize(32),\n",
        "                T.CenterCrop(32),\n",
        "\n",
        "                # Convert to tensor and apply normalization:\n",
        "\n",
        "                # YOUR CODE HERE\n",
        "            ]\n",
        "        ),\n",
        "        # Identical to the valid set in this case\n",
        "        \"test\": T.Compose(\n",
        "            [\n",
        "                T.Resize(32),\n",
        "                T.CenterCrop(32),\n",
        "\n",
        "                # Convert to tensor and apply normalization:\n",
        "\n",
        "                # YOUR CODE HERE\n",
        "            ]\n",
        "        ),\n",
        "    }\n",
        "\n",
        "\n",
        "def get_data_loaders(batch_size, valid_size, transforms, num_workers, random_seed=42):\n",
        "\n",
        "    # Reseed random number generators to get a deterministic split. This is useful\n",
        "    # when comparing experiments, so you'll know they all run on the same data.\n",
        "    # In principle you should repeat this a few times (cross validation) to see\n",
        "    # the variability of your measurements, but we won't do this here for simplicity\n",
        "    torch.manual_seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    # Get the CIFAR10 training dataset from torchvision.datasets and set the transforms\n",
        "    # We will split this further into train and validation in this function\n",
        "    train_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['train'])\n",
        "    valid_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms['valid'])\n",
        "\n",
        "    # Compute how many items we will reserve for the validation set\n",
        "    n_tot = len(train_data)\n",
        "    split = int(np.floor(valid_size * n_tot))\n",
        "\n",
        "    # compute the indices for the training set and for the validation set\n",
        "    shuffled_indices = torch.randperm(n_tot)\n",
        "    train_idx, valid_idx = shuffled_indices[split:], shuffled_indices[:split]\n",
        "\n",
        "    # define samplers for obtaining training and validation batches\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    # prepare data loaders (combine dataset and sampler)\n",
        "    # NOTE that here we use train_data for the train dataloader but valid_data\n",
        "    # for the valid_loader, so the respective transforms are applied\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    test_data = datasets.CIFAR10(\"data\", train=False, download=True, transform=transforms['test'])\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_data, batch_size=batch_size, num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return {'train': train_loader, 'valid': valid_loader, 'test': test_loader}\n",
        "\n",
        "# specify the image classes\n",
        "classes = [\n",
        "    \"airplane\",\n",
        "    \"automobile\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgr4akFwV4zZ"
      },
      "source": [
        "# Model Definition\n",
        "\n",
        "Here we use a model very similar to the one we used before, but we add Batch Normalization that makes our training faster and more robust, and also allows us to go deeper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2MdtnsrV4zZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_classes=10):\n",
        "\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "            # Add batch normalization (BatchNorm2d) here\n",
        "            # YOUR CODE HERE\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1),  # -> 32x16x16\n",
        "            # Add batch normalization (BatchNorm2d) here\n",
        "            # YOUR CODE HERE\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # -> 32x8x8\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),  # -> 64x8x8\n",
        "            # Add batch normalization (BatchNorm2d) here\n",
        "            # YOUR CODE HERE\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # -> 64x4x4\n",
        "\n",
        "            # Since we are using BatchNorm and data augmentation,\n",
        "            # we can go deeper than before and add one more conv layer\n",
        "            nn.Conv2d(64, 128, 3, padding=1),  # -> 128x4x4\n",
        "            # Add batch normalization (BatchNorm2d) here\n",
        "            # YOUR CODE HERE\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # -> 128x2x2\n",
        "\n",
        "            nn.Flatten(),  # -> 1x64x4x4\n",
        "\n",
        "            nn.Linear(128 * 2 * 2, 500),  # -> 500\n",
        "            nn.Dropout(0.5),\n",
        "            # Add batch normalization (BatchNorm1d, NOT BatchNorm2d) here\n",
        "            # YOUR CODE HERE\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Just call the model on x here:\n",
        "        # YOUR CODE HERE\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# create a complete CNN\n",
        "model = Net()\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf9QoZnAV4za"
      },
      "source": [
        "---\n",
        "# Learning Rate Finder\n",
        "\n",
        "Before we start our training, let's find a range for the learning rate that makes sense for our situation. We will use the learning rate finder that we've seen in one of the previous videos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TzRQNnJV4zb"
      },
      "outputs": [],
      "source": [
        "# Feel free to look into the code of lr_finder and see how it works!\n",
        "from lr_finder import lr_finder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 64\n",
        "valid_size = 0.2\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "\n",
        "transforms = get_transforms(rand_augment_magnitude=9)\n",
        "data_loaders = get_data_loaders(batch_size, valid_size, transforms, num_workers)\n",
        "\n",
        "# Range  and number of steps for the learning rate\n",
        "min_lr = 1e-5\n",
        "max_lr = 1\n",
        "n_steps = min(len(data_loaders['train']), 200)\n",
        "\n",
        "# specify loss function (categorical cross-entropy)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "losses = lr_finder(min_lr, max_lr, n_steps, loss, model, data_loaders)\n",
        "\n",
        "# Plot the results\n",
        "plt.plot(losses.keys(), losses.values())\n",
        "plt.xscale(\"log\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"learning rate (log scale)\")\n",
        "\n",
        "# Adjust the range on the y-axis to see things more clearly\n",
        "plt.xlim([1e-4, None])\n",
        "plt.ylim([min(losses.values()), np.percentile(list(losses.values()), 97)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVTiYFGUV4zb"
      },
      "source": [
        "Remember that a good initial choice for the learning rate is in the middle of the steep part. In this case it seems that 0.04 is a good initial choice.\n",
        "\n",
        "# Learning Rate Scheduler + Hyperparameter Optimization\n",
        "Let's also use two other tricks we have just learned: the learning rate scheduler, that changes the learning rate as the training progresses, and the hyperparameter optimization that optimizes the choices to maximize performance.\n",
        "\n",
        "Let's start by writing an optimize function that leverages the Learning Rate scheduler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwqEi5n9V4zc"
      },
      "outputs": [],
      "source": [
        "from livelossplot import PlotLosses\n",
        "from livelossplot.outputs import MatplotlibPlot\n",
        "from helpers import train_one_epoch, valid_one_epoch\n",
        "import torch.optim\n",
        "\n",
        "\n",
        "def optimize(data_loaders, model, optimizer, loss, n_epochs, save_path, interactive_tracking=False):\n",
        "\n",
        "    # This is a plotting function\n",
        "    def after_subplot(ax: plt.Axes, group_name: str, x_label: str):\n",
        "        \"\"\"Add title xlabel and legend to single chart\"\"\"\n",
        "        ax.set_title(group_name)\n",
        "        ax.set_xlabel(x_label)\n",
        "        ax.legend(loc=\"center right\")\n",
        "\n",
        "    # initialize tracker for minimum validation loss\n",
        "    if interactive_tracking:\n",
        "        liveloss = PlotLosses(outputs=[MatplotlibPlot(after_subplot=after_subplot)])\n",
        "    else:\n",
        "        liveloss = None\n",
        "\n",
        "    valid_loss_min = None\n",
        "    logs = {}\n",
        "\n",
        "    # Learning rate scheduler: setup a learning rate scheduler that\n",
        "    # reduces the learning rate when the validation loss reaches a\n",
        "    # plateau. Use torch.optim.lr_scheduler.ReduceLROnPlateau, with\n",
        "    # a treshold of 0.01. Look at the docs if in doubt:\n",
        "    # https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        train_loss = train_one_epoch(\n",
        "            data_loaders[\"train\"], model, optimizer, loss\n",
        "        )\n",
        "\n",
        "        valid_loss = valid_one_epoch(data_loaders[\"valid\"], model, loss)\n",
        "\n",
        "        # If the validation loss decreases by more than 1%, save the model\n",
        "        if valid_loss_min is None or (\n",
        "                (valid_loss_min - valid_loss) / valid_loss_min > 0.01\n",
        "        ):\n",
        "\n",
        "            # Save the weights to save_path\n",
        "            torch.save(model.state_dict(), save_path)  # -\n",
        "\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "        # Update learning rate, i.e., make a step in the learning rate scheduler\n",
        "        # Remember to use the validation loss, so that the learning rate scheduler\n",
        "        # will change the learning rate when the validation loss is not\n",
        "        # decreasing anymore\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Log the losses and the current learning rate\n",
        "        if interactive_tracking:\n",
        "            logs[\"loss\"] = train_loss\n",
        "            logs[\"val_loss\"] = valid_loss\n",
        "            logs[\"lr\"] = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "            liveloss.update(logs)\n",
        "            liveloss.send()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZZvy2sWV4zc"
      },
      "source": [
        "Now let's write a function that trains and validates our model given some hyperparameters. Let's consider for simplicity just two hyperparameters: the learning rate and the strength of the data augmentation in `RandAugment`.\n",
        "\n",
        "We are also going to track our experiments with `mlflow`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6U6yVsQV4zd"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from helpers import one_epoch_test\n",
        "\n",
        "def train_one_model(learning_rate, rand_augment_magnitude, n_epochs):\n",
        "\n",
        "    transforms = get_transforms(rand_augment_magnitude=rand_augment_magnitude)\n",
        "    data_loaders = get_data_loaders(batch_size, valid_size, transforms, num_workers)\n",
        "    model = Net()\n",
        "\n",
        "    if train_on_gpu:\n",
        "        model.cuda()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    with mlflow.start_run():\n",
        "\n",
        "        optimize(data_loaders, model, optimizer, loss, n_epochs, \"best_val_loss.pt\", interactive_tracking=True)\n",
        "\n",
        "        # Restore best validation loss\n",
        "        model.load_state_dict(torch.load('best_val_loss.pt'))\n",
        "\n",
        "        # Test model on *validation* set (never optimize your hyperparameters on the\n",
        "        # test set!)\n",
        "        val_loss, preds, actuals = one_epoch_test(data_loaders['valid'], model, loss)\n",
        "\n",
        "        # Use mlflow.log_param to log the learning rate and the\n",
        "        # rand_augment_magnitude\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Use mlflow.log_metric to log your validation loss\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        val_accuracy = (np.array(preds)==np.array(actuals)).sum() / len(actuals)\n",
        "\n",
        "        # Use mlflow to log the validation accuracy as a metric\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Use mlflow.log_artifact to log the best_val_loss.pt file\n",
        "        # YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BSRgfRKV4zd"
      },
      "source": [
        "## Random Search\n",
        "Let's use the random search technique to explore our hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVz4EA9jV4zd"
      },
      "outputs": [],
      "source": [
        "# Make a random grid of learning rate and rand_augment_magnitude\n",
        "min_lr = 0.01\n",
        "max_lr = 0.1\n",
        "\n",
        "# Here you can decide how many experiments to run\n",
        "# Run between 5 and 20. The more you run the better\n",
        "# your results might be, but of course it will take\n",
        "# longer\n",
        "# Normally you would use a lot more than that, which is why\n",
        "# you typically do hyperparam optimization in the cloud so\n",
        "# all the experiments can run in parallel\n",
        "n_grid = # YOUR CODE HERE\n",
        "\n",
        "# Sample log-uniformly the learning rate\n",
        "lrs = 10**(np.random.uniform(np.log10(min_lr), np.log10(max_lr), n_grid))\n",
        "# Sample uniformly the rand augment transform strength\n",
        "r_a_mag = np.random.randint(1, 15, n_grid)\n",
        "\n",
        "# Plot our grid\n",
        "_ = plt.scatter(lrs, r_a_mag)\n",
        "_ = plt.xscale(\"log\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzAvmFokV4ze"
      },
      "outputs": [],
      "source": [
        "# Run our experiments\n",
        "for lr, rand_aug_mag in zip(lrs, r_a_mag):\n",
        "    train_one_model(lr, rand_aug_mag, n_epochs=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnkjvtTGV4zf"
      },
      "source": [
        "We can now see the results of our experiments. If you are running locally, you could now run `mlflow ui` to explore the results. If you are in the Udacity workspace, use the following code that reads the results and return them as a pandas DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEJO7_W8V4zf"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "runs = mlflow.search_runs()\n",
        "sorted_runs = runs[\n",
        "    [\n",
        "        \"run_id\",\n",
        "        \"params.learning_rate\",\n",
        "        \"params.rand_augment_magnitude\",\n",
        "        \"metrics.val_loss\",\n",
        "        \"metrics.val_accuracy\",\n",
        "    ]\n",
        "].sort_values(by='metrics.val_loss')\n",
        "sorted_runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfVDUa4pV4zg"
      },
      "outputs": [],
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# Get the id with the lowest val_loss\n",
        "lowest_loss_id = sorted_runs.iloc[0]['run_id']\n",
        "\n",
        "# Fetch the best model from that run\n",
        "client = MlflowClient()\n",
        "local_path = client.download_artifacts(lowest_loss_id, \"best_val_loss.pt\", '.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds_UT8ZMV4zg"
      },
      "source": [
        "###  Load the Model with the Lowest Validation Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkpTSt6qV4zg"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best_val_loss.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYmBtQFNV4zg"
      },
      "source": [
        "---\n",
        "## Test the Trained Network\n",
        "\n",
        "Test your trained model on previously unseen data! A \"good\" result will be a CNN that gets around 70% (or more, try your best!) accuracy on these test images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRrww3oPV4zh"
      },
      "outputs": [],
      "source": [
        "from helpers import one_epoch_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wcC5cJ1V4zh"
      },
      "outputs": [],
      "source": [
        "# Test Accuracy: 77% (7701/10000)\n",
        "\n",
        "test_loss, preds, actuals = one_epoch_test(data_loaders['test'], model, loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGooWWtJV4zh"
      },
      "outputs": [],
      "source": [
        "from helpers import plot_confusion_matrix\n",
        "\n",
        "cm = plot_confusion_matrix(preds, actuals, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmTN7-kVV4zh"
      },
      "source": [
        "We have improved on our previous results by almost 5%. There is a lot more that can be done, feel free to keep experimenting with different augmentations for example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7sSt4YWV4zh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}